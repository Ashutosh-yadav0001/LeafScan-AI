==========================================================
PLANT DISEASE CLASSIFICATION USING DEEP LEARNING
A CNN-Based Approach for Potato and Tomato Crops
==========================================================

Author: Ashutosh Yadav (Roll Number: XXXXX)
Term Project Report | Trimester 7
B.Sc. (Honours) Data Science and Artificial Intelligence
Indian Institute of Technology Guwahati, India
Email: ashutosh@op.iitg.ac.in

==========================================================
ABSTRACT
==========================================================

This report presents a deep learning-based approach for automated classification of plant leaf diseases in potato and tomato crops. Agricultural productivity is significantly impacted by plant diseases, causing substantial economic losses worldwide. Early and accurate detection is crucial for effective crop management. 

We developed a Convolutional Neural Network (CNN) model trained on the PlantVillage dataset, capable of classifying 13 disease categories across potato and tomato plants. The system achieves 97.2% accuracy for potato and 89.6% for tomato on full dataset evaluation. Additionally, we implemented a complete web application with a FastAPI backend and React frontend, enabling farmers to upload leaf images and receive instant disease predictions with confidence scores. The deployed system demonstrates the practical applicability of deep learning in precision agriculture.

Keywords: Deep Learning, Convolutional Neural Networks, Plant Disease Classification, Computer Vision, Agricultural AI, TensorFlow

==========================================================
1. INTRODUCTION
==========================================================

Agriculture forms the backbone of many economies worldwide, with potato and tomato being among the most widely cultivated crops globally. However, plant diseases pose a significant threat to crop yields, potentially causing losses of 20-40% annually. Traditional disease identification relies on expert knowledge and manual inspection, which is time-consuming, subjective, and not scalable.

Recent advances in deep learning, particularly Convolutional Neural Networks (CNNs), have demonstrated remarkable success in image classification tasks. These techniques can be leveraged to develop automated systems for plant disease detection, enabling early intervention and reducing crop losses.

This project develops an end-to-end plant disease classification system that accurately identifies diseases in potato and tomato leaves from images. The system combines a trained CNN model with a user-friendly web interface, making it accessible to farmers without specialized technical knowledge.

Key Contributions:
• CNN model achieving 97.2% (potato) and 89.6% (tomato) accuracy on 13 disease classes
• Data augmentation techniques for improved model generalization
• Complete web application for real-time disease prediction
• Deployment using modern technologies (FastAPI, React)

==========================================================
2. PROBLEM STATEMENT AND OBJECTIVES
==========================================================

2.1 Problem Statement
---------------------
Given an image of a plant leaf (potato or tomato), classify it into one of the predefined disease categories or identify it as healthy.

The system must:
• Handle images of varying quality and lighting conditions
• Provide predictions with confidence scores
• Operate in real-time through a web interface
• Generalize well to unseen images

Disease Classes:
• Potato (3 classes): Early Blight, Late Blight, Healthy
• Tomato (10 classes): Bacterial Spot, Early Blight, Late Blight, Leaf Mold, Septoria Leaf Spot, Spider Mites, Target Spot, Mosaic Virus, Yellow Leaf Curl Virus, Healthy

2.2 Objectives
--------------
1. To study existing approaches for plant disease classification
2. To design and implement a CNN-based classification model
3. To apply data augmentation techniques to improve model robustness
4. To develop a web-based application for real-time prediction
5. To evaluate performance using accuracy, precision, and recall

==========================================================
3. METHODOLOGY / APPROACH
==========================================================

3.1 Overall Workflow
--------------------
The proposed system follows a structured pipeline comprising five key stages:

Stage 1: Data Collection
   └── Download PlantVillage dataset from Kaggle
   └── Organize images into class-specific folders
   └── Verify image quality and remove corrupted files

Stage 2: Data Preprocessing
   └── Resize images to uniform 256×256 pixels
   └── Normalize pixel values to [0, 1] range
   └── Split data into train/validation/test sets

Stage 3: Data Augmentation
   └── Apply random transformations
   └── Increase dataset diversity
   └── Prevent model overfitting

Stage 4: Model Training
   └── Build CNN architecture
   └── Train using GPU acceleration
   └── Monitor validation metrics

Stage 5: Deployment
   └── Save trained model
   └── Build REST API
   └── Create web interface

3.2 Dataset Description
-----------------------
We utilized the PlantVillage dataset, a publicly available benchmark containing 54,306 images of plant leaves across 38 disease categories. This dataset was collected under controlled laboratory conditions with consistent lighting and background.

Dataset Characteristics:
• Image Format: JPEG/PNG
• Original Resolution: Variable (224×224 to 512×512)
• Color Space: RGB (3 channels)
• License: Open access for research

For this project, we extracted:
• Potato subset: 3 classes, 2,152 images
• Tomato subset: 10 classes, 18,160 images

Disease Classes Distribution:
+----------+----------------------------+--------+----------+
| Crop     | Disease Class              | Images | % of Set |
+----------+----------------------------+--------+----------+
| Potato   | Early Blight (Alternaria)  | 1,000  | 46.5%    |
| Potato   | Late Blight (Phytophthora) | 1,000  | 46.5%    |
| Potato   | Healthy                    | 152    | 7.0%     |
+----------+----------------------------+--------+----------+
| Tomato   | Bacterial Spot             | 2,127  | 11.7%    |
| Tomato   | Early Blight               | 1,000  | 5.5%     |
| Tomato   | Late Blight                | 1,909  | 10.5%    |
| Tomato   | Leaf Mold                  | 952    | 5.2%     |
| Tomato   | Septoria Leaf Spot         | 1,771  | 9.8%     |
| Tomato   | Spider Mites (Two-spotted) | 1,676  | 9.2%     |
| Tomato   | Target Spot                | 1,404  | 7.7%     |
| Tomato   | Mosaic Virus               | 373    | 2.1%     |
| Tomato   | Yellow Leaf Curl Virus     | 5,357  | 29.5%    |
| Tomato   | Healthy                    | 1,591  | 8.8%     |
+----------+----------------------------+--------+----------+

Data Partitioning Strategy:
• Training Set: 80% (used for model learning)
• Validation Set: 10% (used for hyperparameter tuning)
• Test Set: 10% (used for final evaluation)

The split was performed using stratified sampling to maintain class distribution across all sets, ensuring balanced representation of minority classes.

3.3 Data Preprocessing Pipeline
-------------------------------
Step 1: Image Loading
   • Read images using TensorFlow's image_dataset_from_directory()
   • Automatic label inference from folder names
   • Batch loading for memory efficiency

Step 2: Resizing
   • Standardize all images to 256×256 pixels
   • Maintain aspect ratio using center cropping
   • Bilinear interpolation for smooth scaling

Step 3: Normalization
   • Rescale pixel values from [0, 255] to [0, 1]
   • Formula: normalized_pixel = pixel / 255.0
   • Improves gradient flow during training

Step 4: Caching & Prefetching
   • Cache preprocessed images in memory
   • Prefetch next batch during GPU computation
   • Reduces I/O bottleneck significantly

3.4 Data Augmentation Techniques
--------------------------------
To address class imbalance and prevent overfitting, we implemented real-time data augmentation using TensorFlow's experimental preprocessing layers:

Augmentation Operations:
+------------------------+-------------+----------------------------------+
| Technique              | Parameters  | Purpose                          |
+------------------------+-------------+----------------------------------+
| Random Horizontal Flip | p=0.5       | Simulate leaf orientation        |
| Random Vertical Flip   | p=0.5       | Increase positional invariance   |
| Random Rotation        | ±20%        | Handle camera angle variations   |
| Random Zoom            | ±20%        | Simulate distance variations     |
| Random Contrast        | factor=0.2  | Handle lighting conditions       |
+------------------------+-------------+----------------------------------+

Key Benefits:
• Artificially expands training dataset by 10-20x
• Reduces overfitting on training samples
• Improves model generalization to real-world images
• No additional storage required (applied on-the-fly)

3.5 CNN Model Architecture
--------------------------
We designed a custom Convolutional Neural Network inspired by VGG architecture principles, optimized for plant disease classification.

Architecture Design Philosophy:
• Progressive increase in filter depth (32 → 64)
• Small 3×3 kernels for fine-grained feature extraction
• MaxPooling for spatial dimension reduction
• ReLU activation for non-linearity

Detailed Layer Configuration:
+-----+----------------------+----------------+------------+-------------+
| #   | Layer Type           | Output Shape   | Parameters | Activation  |
+-----+----------------------+----------------+------------+-------------+
| 1   | InputLayer           | 256×256×3      | 0          | -           |
| 2   | Rescaling (1/255)    | 256×256×3      | 0          | -           |
| 3   | Data Augmentation    | 256×256×3      | 0          | -           |
| 4   | Conv2D (32, 3×3)     | 254×254×32     | 896        | ReLU        |
| 5   | MaxPooling2D (2×2)   | 127×127×32     | 0          | -           |
| 6   | Conv2D (64, 3×3)     | 125×125×64     | 18,496     | ReLU        |
| 7   | MaxPooling2D (2×2)   | 62×62×64       | 0          | -           |
| 8   | Conv2D (64, 3×3)     | 60×60×64       | 36,928     | ReLU        |
| 9   | MaxPooling2D (2×2)   | 30×30×64       | 0          | -           |
| 10  | Conv2D (64, 3×3)     | 28×28×64       | 36,928     | ReLU        |
| 11  | MaxPooling2D (2×2)   | 14×14×64       | 0          | -           |
| 12  | Conv2D (64, 3×3)     | 12×12×64       | 36,928     | ReLU        |
| 13  | MaxPooling2D (2×2)   | 6×6×64         | 0          | -           |
| 14  | Conv2D (64, 3×3)     | 4×4×64         | 36,928     | ReLU        |
| 15  | MaxPooling2D (2×2)   | 2×2×64         | 0          | -           |
| 16  | Flatten              | 256            | 0          | -           |
| 17  | Dense (64)           | 64             | 16,448     | ReLU        |
| 18  | Dense (N classes)    | N              | 195/650    | Softmax     |
+-----+----------------------+----------------+------------+-------------+

Total Parameters: ~183,747 (Potato) / ~184,102 (Tomato)
Trainable Parameters: 100%

Feature Extraction Process:
• Convolutional layers extract hierarchical features:
  - Early layers: edges, colors, textures
  - Middle layers: shapes, patterns
  - Deep layers: disease-specific features (spots, lesions)
• MaxPooling reduces spatial dimensions while retaining important features
• Flatten converts 2D feature maps to 1D vector for classification

3.6 Training Configuration
--------------------------
Hyperparameters:
+----------------------+------------------+
| Parameter            | Value            |
+----------------------+------------------+
| Optimizer            | Adam             |
| Learning Rate        | 0.001 (default)  |
| Loss Function        | Sparse CCE       |
| Batch Size           | 32               |
| Epochs               | 15               |
| Input Size           | 256×256×3        |
+----------------------+------------------+

Loss Function - Sparse Categorical Cross-Entropy:
L = -∑(y_true × log(y_pred))

Where:
• y_true = one-hot encoded ground truth label
• y_pred = predicted probability distribution

Optimization Details:
• Adam optimizer adapts learning rate per parameter
• Exponential decay of first and second moment estimates
• Helps escape local minima and saddle points

3.7 Evaluation Metrics
----------------------
We evaluated model performance using multiple metrics:

1. Accuracy = (TP + TN) / (TP + TN + FP + FN)
   - Overall correctness of predictions

2. Precision = TP / (TP + FP)
   - Proportion of positive predictions that are correct

3. Recall = TP / (TP + FN)
   - Proportion of actual positives correctly identified

4. F1-Score = 2 × (Precision × Recall) / (Precision + Recall)
   - Harmonic mean of precision and recall

Where:
• TP = True Positives, TN = True Negatives
• FP = False Positives, FN = False Negatives

3.8 Web Application Architecture
--------------------------------
The deployment follows a three-tier architecture:

TIER 1: Presentation Layer (Frontend)
+------------------------------------------+
| React.js Application                     |
| • Material-UI Components                 |
| • Drag-and-drop image upload             |
| • Real-time prediction display           |
| • Responsive design for mobile/desktop   |
+------------------------------------------+
           ↓ HTTP POST (multipart/form-data)
           
TIER 2: Application Layer (Backend)
+------------------------------------------+
| FastAPI Server                           |
| • REST API endpoints                     |
| • Image preprocessing                    |
| • Model inference using TensorFlow       |
| • JSON response generation               |
+------------------------------------------+
           ↓ Model.predict()
           
TIER 3: Data Layer (Model)
+------------------------------------------+
| TensorFlow SavedModel                    |
| • Pre-trained CNN weights                |
| • Saved in SavedModel format             |
| • GPU-accelerated inference              |
+------------------------------------------+

API Endpoint Specification:
• URL: POST /predict
• Input: Image file (JPEG/PNG)
• Output: JSON {class: "disease_name", confidence: 0.95}

System Flow:
1. User uploads leaf image through web interface
2. Frontend sends image to FastAPI backend
3. Backend preprocesses image (resize, normalize)
4. CNN model performs inference
5. Prediction with confidence score returned
6. Frontend displays result with disease information

==========================================================
4. EXPERIMENTS AND RESULTS
==========================================================

4.1 Experimental Setup
----------------------
Hardware: NVIDIA GeForce RTX 3050 GPU (4GB VRAM)
Software: Python 3.10, TensorFlow 2.10.1, CUDA 11.2

4.2 Results
-----------
Model Performance Summary:

+----------+------------+----------+------------------+---------+
| Model    | Train Acc  | Val Acc  | Full Dataset Acc | Classes |
+----------+------------+----------+------------------+---------+
| Potato   | 98.2%      | 96.5%    | 97.2%            | 3       |
| Tomato   | 95.8%      | 92.3%    | 89.6%            | 10      |
+----------+------------+----------+------------------+---------+

The training curves showed consistent improvement with minimal overfitting, demonstrating effective data augmentation.

==========================================================
5. DISCUSSION
==========================================================

The experimental results confirm CNN effectiveness for plant disease classification:

Performance Analysis:
The potato model (97.2% on full dataset) outperformed tomato (89.6%) due to fewer classes (3 vs 10), making classification inherently easier.

Data Augmentation Impact:
Without augmentation, validation accuracy plateaued at ~80%. Augmentation improved it by 12-15%.

Challenges Encountered:
• GPU setup required specific CUDA/cuDNN compatibility
• Some diseases share visual similarities (Early vs Late Blight)
• Real-world images may differ from controlled dataset

Limitations:
• Currently limited to potato and tomato only
• Requires good image quality for reliable predictions
• Multiple simultaneous diseases not tested

==========================================================
6. CONCLUSION AND FUTURE WORK
==========================================================

This project successfully developed a deep learning-based plant disease classification system achieving 97.2% accuracy for potato and 89.6% for tomato disease classification.

Key Achievements:
• Trained CNN models for 13 disease classes
• Implemented effective data augmentation
• Developed complete web application for real-time use
• Demonstrated AI applicability in precision agriculture

Future Work:
1. Extend to additional crops (wheat, rice, corn)
2. Implement transfer learning (ResNet, EfficientNet)
3. Develop mobile application for field use
4. Add disease management recommendations

==========================================================
7. ARTIFACTS AND DEMONSTRATIONS
==========================================================

• Code Repository: https://github.com/Ashutosh-yadav0001/Pototo-disease
• Dataset: PlantVillage Dataset (Kaggle)
• Technologies: Python, TensorFlow, FastAPI, React.js

Note: AI tools (Gemini) were used to enhance productivity. All work reflects original understanding and implementation.

==========================================================
REFERENCES
==========================================================

[1] Hughes, D. P., & Salathé, M. (2015). An open access repository of images on plant health to enable the development of mobile disease diagnostics. arXiv preprint arXiv:1511.08060.

[2] Mohanty, S. P., Hughes, D. P., & Salathé, M. (2016). Using deep learning for image-based plant disease detection. Frontiers in Plant Science, 7, 1419.

[3] LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.

[4] Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. Advances in Neural Information Processing Systems, 25, 1097-1105.

[5] TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. https://www.tensorflow.org/

==========================================================
